#Vocabulary Analyzer

---

##开发进程

该工具是一个在线工具，浏览器打开即可用，粘贴文本后能够自动分析出文件中包含的高难度词汇。该网站的前身是一个Windows端的小程序，由于该程序的运行需要安装运行环境，我为了方便使用把运行环境直接打包了，所以软件包30多兆，挺大的，而且也没有考虑到64位系统，所以给大家使用带来了诸多不便，于是我就想做个在线的，打开即用，方便快捷。因为我学Linux底层学的比较多，却不会Web开发，所以首先考虑用Python写个简单的文件上传服务器，结果发现功能实现以后占用内存比较大，小型VPS承受不起。后来恰好看到了OpenShift对于Python开发的说明，知道了wsgi这个框架，看了几篇教程后迅速做出了成品，从此我也是能开发Web应用的人了。

##功能介绍

该在线工具是基于内置的词库来识别生词的。词库里面的单词是由**专四、专八、托福、雅思、SAT、GRE**的核心词汇表经过合并、排序、去重而来的，总计11567个单词，基本上全是比较难的词汇，但也不排除里面含有个别的四六级低阶词汇。

##使用方法

### 运行环境

Python 版本 3.5

安装 NLTK 自然语言处理工具

### 运行方法

下载运行后用浏览器打开`http://localhost:8051/VocabularyAnalyzer`即可。